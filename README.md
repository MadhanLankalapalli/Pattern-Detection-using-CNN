# ğŸ”¬ Pattern Detection Using CNN â€” RTL Hardware Implementation

> *A hardware-efficient Convolutional Neural Network implemented at Register Transfer Level (RTL) in Verilog HDL, enabling real-time object recognition on FPGA platforms.*

---

## Abstract

Modern edge AI demands inference engines that are **fast, deterministic, and power-conscious** â€” constraints that software CNNs running on CPUs or GPUs frequently fail to meet. This work presents a fully synchronous, pipelined CNN architecture synthesized in Verilog HDL, designed to detect and count occurrences of a predefined **8Ã—8 test pattern** within a **128Ã—128 grayscale image**.

The pipeline integrates Laplacian edge enhancement, pattern-matching convolution, max pooling, and threshold-based detection â€” validated through RTL simulation and confirmed operable at **155.67 MHz**, making it a compelling candidate for FPGA-based embedded vision systems.

---

## Motivation

> *"Why hardware, when software works?"*

Software CNNs offer flexibility, but at the cost of latency, power, and unpredictability. RTL-level design trades generality for precision â€” delivering:

- âš¡ **Deterministic, cycle-accurate latency**
- ğŸ”‹ **Minimal power footprint for edge deployment**
- ğŸš€ **True parallel execution â€” not simulated parallelism**

This project bridges the gap between algorithmic CNN theory and physical silicon-level execution, demonstrating that even constrained hardware can perform meaningful visual intelligence.

---

## System Specifications

| Parameter | Specification |
|---|---|
| Input Image | 128 Ã— 128 pixels (Grayscale) |
| Test Pattern | 8 Ã— 8 pixels |
| Pixel Precision | 8-bit unsigned |
| Output | Count of detected pattern matches |

---

## CNN Processing Pipeline

The system follows a four-stage processing cascade, each stage implemented as a dedicated RTL module with pipeline registers at boundaries:

```
  [Input Image 128Ã—128]
          â”‚
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Stage 1          â”‚  Laplacian 3Ã—3 Convolution
  â”‚  Edge Enhancement â”‚  â†’ Image: 126Ã—126 | Pattern: 6Ã—6
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Stage 2          â”‚  Pattern-Matching Convolution (6Ã—6)
  â”‚  Feature Mapping  â”‚  â†’ Feature Map: 121Ã—121
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Stage 3          â”‚  2Ã—2 Max Pooling
  â”‚  Spatial Reductionâ”‚  â†’ Pooled Map: 60Ã—60
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Stage 4          â”‚  Threshold @ 25% of Self-Convolution
  â”‚  Detection & Countâ”‚  â†’ Match Count Output
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Architecture Deep Dive

### Stage 1 â€” Laplacian Convolution (Edge Enhancement)

A 3Ã—3 Laplacian kernel is independently applied to both the input image and the test pattern, sharpening edges and suppressing uniform regions. This step is critical â€” raw pixel matching is noise-sensitive; **edge-space matching is structurally robust**.

- Image output: **126 Ã— 126**
- Pattern output: **6 Ã— 6**

<p align="center">
  <img src="images/cov_stage1.png" width="700"><br>
  <i>Fig. 1 â€” RTL Architecture of Laplacian Convolution</i>
</p>

---

### Stage 2 â€” Pattern Matching Convolution

The Laplacian-processed image is convolved with the 6Ã—6 processed pattern kernel. A **parallel multiplier array** feeds a **hierarchical adder tree**, maximizing throughput with minimal logic depth.

- Output feature map: **121 Ã— 121**
- Fully pipelined for sustained single-cycle-per-window throughput

<p align="center">
  <img src="images/cov_stage2.png" width="500"><br>
  <i>Fig. 2 â€” Pattern Matching Convolution Architecture</i>
</p>

---

### Stage 3 â€” Max Pooling

A 2Ã—2 max pooling layer performs spatial downsampling, suppressing weak activations and retaining dominant pattern responses.

- Output: **60 Ã— 60**
- Implemented as a one-cycle comparator per pooling window

<p align="center">
  <img src="images/maxpooling.png" width="300"><br>
  <i>Fig. 3 â€” Max Pooling RTL Architecture</i>
</p>

---

### Stage 4 â€” Thresholding & Detection

Each pooled activation is compared against a threshold derived as **25% of the pattern's self-convolution score** â€” a normalized, input-adaptive criterion. Activations exceeding this threshold register as confirmed matches, and a running counter accumulates the final detection count.

---

## Hardware Implementation

### Design Philosophy

This design is built around three RTL principles:

**Pipelining** â€” Each convolution stage is broken into sub-stages with registered boundaries, maximizing clock frequency without stalling the datapath.

**Parallelism** â€” All multiplications within a convolution window execute simultaneously; the hierarchical adder tree compresses 36 partial products in O(log n) levels.

**Bit-Width Optimization** â€” Arithmetic is performed at 16â€“22 bits, carefully selected to prevent overflow while avoiding costly 32-bit operations.

### Toolchain

| Tool | Purpose |
|---|---|
| Verilog HDL | RTL Design |
| Xilinx Vivado | Simulation, Synthesis, Timing Analysis |
| RTL Simulation | Functional Verification |

---

## Results

| Metric | Value |
|---|---|
| Maximum Clock Frequency | **155.67 MHz** |
| Total Latency | ~37,722 clock cycles |
| Pooling Output Dimensions | 60 Ã— 60 |
| Detection Accuracy | Verified via RTL simulation |

<p align="center">
  <img src="images/waveform.png" width="700"><br>
  <i>Fig. 4 â€” Timing Diagram of CNN Top Module</i>
</p>

At 155.67 MHz, the design processes one image in approximately **242 Âµs** â€” well within the real-time threshold for most embedded vision tasks.

---

## Applications

This architecture is directly applicable to:

- **FPGA-based vision accelerators** â€” autonomous vehicles, drones, industrial inspection
- **Embedded AI systems** â€” smart cameras, IoT endpoints
- **Robotics** â€” real-time object localization and tracking
- **Surveillance** â€” low-power, always-on scene monitoring
- **Medical Imaging** â€” preprocessing pipelines for anomaly detection

---

## Future Work

| Enhancement | Impact |
|---|---|
| Multi-pattern detection support | Extend utility to complex scene understanding |
| AXI-stream interface | Enable SoC integration with ARM processors |
| FPGA deployment on Zynq-7000 | Full end-to-end hardware validation |
| Power & area optimization | Reduce resource footprint for resource-constrained FPGAs |
| Noise-robust preprocessing | Improve reliability under real-world imaging conditions |

---

## Authors

**Lankalapalli Madhan** Â· Bhavanam Naga Varshitha Â· Koram Rupalakshmi

**Supervisor:** Mr. K. Shivalal  
Department of Electronics and Communication Engineering  
**RGUKT Nuzvid**

---

<p align="center">
  <i>Built at the intersection of digital design and machine intelligence.</i>
</p>
